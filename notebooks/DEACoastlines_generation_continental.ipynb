{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DEA Coastlines continental hotspots <img align=\"right\" src=\"https://github.com/GeoscienceAustralia/dea-notebooks/raw/develop/Supplementary_data/dea_logo.jpg\">\n",
    "\n",
    "This code combines individual datasets into continental DEA Coastlines layers:\n",
    "* Combines output shorelines and rates of change statistics point vectors into single continental datasets\n",
    "* Aggregates this data to produce moving window hotspot datasets that summarise coastal change at regional and continental scale.\n",
    "\n",
    "This is an interactive version of the code intended for prototyping; to run this analysis at scale, use the [command line tools](DEACoastlines_generation_CLI.ipynb).\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "Set working directory to top level of repo to ensure links work correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/Robbi/dea-coastlines\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "\n",
    "First we import the required Python packages, then we connect to the database, and load the catalog of virtual products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.in --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext line_profiler\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "\n",
    "from coastlines.vector import points_on_line, change_regress\n",
    "from coastlines.utils import STYLES_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_version = \"testing\"\n",
    "continental_version = \"testing\"\n",
    "baseline_year = 2020\n",
    "hotspots_radius = [2000, 500, 100]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make output directory and identify files to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make output directory \n",
    "output_dir = Path(f\"data/processed/{continental_version}\")\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Setup input and output file paths\n",
    "shoreline_paths = (\n",
    "    f\"data/interim/vector/{vector_version}/*/\" f\"annualshorelines*.shp\"\n",
    ")\n",
    "ratesofchange_paths = (\n",
    "    f\"data/interim/vector/{vector_version}/*/\" f\"ratesofchange*.shp\"\n",
    ")\n",
    "\n",
    "# Output path for geopackage\n",
    "OUTPUT_FILE = output_dir / f\"coastlines_{continental_version}.gpkg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine data\n",
    "### Shorelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning 1: A geometry of type MULTILINESTRING is inserted into layer shorelines_annual of geometry type LINESTRING, which is not normally allowed by the GeoPackage specification, but the driver will however do it. To create a conformant GeoPackage, if using ogr2ogr, the -nlt option can be used to override the layer geometry type. This warning will no longer be emitted for this combination of layer and feature geometry type.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\n",
    "    f\"ogrmerge.py -o \"\n",
    "    f\"{OUTPUT_FILE} {shoreline_paths} \"\n",
    "    f\"-single -overwrite_ds -t_srs epsg:6933 \"\n",
    "    f\"-nln shorelines_annual\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rate of change points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\n",
    "    f\"ogrmerge.py \"\n",
    "    f\"-o {OUTPUT_FILE} {ratesofchange_paths} \"\n",
    "    f\"-single -update -t_srs epsg:6933 \"\n",
    "    f\"-nln rates_of_change\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continental hotspots\n",
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load continental shoreline and rates of change data\n",
    "ratesofchange_gdf = gpd.read_file(OUTPUT_FILE, layer=\"rates_of_change\")\n",
    "shorelines_gdf = gpd.read_file(OUTPUT_FILE, layer=\"shorelines_annual\")\n",
    "\n",
    "# Set year index on coastlines\n",
    "shorelines_gdf = shorelines_gdf.loc[shorelines_gdf.geometry.is_valid].set_index(\"year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop uncertain points from calculation\n",
    "ratesofchange_gdf = ratesofchange_gdf.loc[\n",
    "    ratesofchange_gdf.certainty == \"good\"\n",
    "].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Calculate hotspots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating hotspots at 2000 m\n",
      "Calculating hotspots at 500 m\n",
      "Calculating hotspots at 100 m\n"
     ]
    }
   ],
   "source": [
    "# Convert radius to list if not already\n",
    "hotspots_radius = (\n",
    "    [hotspots_radius] if not isinstance(hotspots_radius, list) else hotspots_radius\n",
    ")\n",
    "\n",
    "for i, radius in enumerate(hotspots_radius):\n",
    "\n",
    "    # Extract hotspot points\n",
    "    print(f\"Calculating hotspots at {radius} m\")\n",
    "    hotspots_gdf = points_on_line(\n",
    "        shorelines_gdf, index=str(baseline_year), distance=int(radius / 2)\n",
    "    )\n",
    "\n",
    "    # Create polygon windows by buffering points\n",
    "    buffered_gdf = hotspots_gdf[[\"geometry\"]].copy()\n",
    "    buffered_gdf[\"geometry\"] = buffered_gdf.buffer(radius)\n",
    "\n",
    "    # Spatial join rate of change points to each polygon\n",
    "    hotspot_grouped = (\n",
    "        ratesofchange_gdf.loc[\n",
    "            :, ratesofchange_gdf.columns.str.contains(\"dist_|geometry\")\n",
    "        ]\n",
    "        .sjoin(buffered_gdf, predicate=\"within\")\n",
    "        .groupby(\"index_right\")\n",
    "    )\n",
    "\n",
    "    # Aggregate/summarise values by taking median of all points\n",
    "    # within each buffered polygon\n",
    "    hotspot_values = hotspot_grouped.median().round(2)\n",
    "\n",
    "    # Extract year from distance columns (remove \"dist_\")\n",
    "    x_years = hotspot_values.columns.str.replace(\"dist_\", \"\").astype(int)\n",
    "\n",
    "    # Compute coastal change rates by linearly regressing annual\n",
    "    # movements vs. time\n",
    "    rate_out = hotspot_values.apply(\n",
    "        lambda row: change_regress(\n",
    "            y_vals=row.values.astype(float), x_vals=x_years, x_labels=x_years\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Add rates of change back into dataframe\n",
    "    hotspot_values[\n",
    "        [\"rate_time\", \"incpt_time\", \"sig_time\", \"se_time\", \"outl_time\"]\n",
    "    ] = rate_out\n",
    "\n",
    "    # Join aggregated values back to hotspot points after\n",
    "    # dropping unused columns (regression intercept)\n",
    "    hotspots_gdf = hotspots_gdf.join(hotspot_values.drop(\"incpt_time\", axis=1))\n",
    "\n",
    "    # Add hotspots radius attribute column\n",
    "    hotspots_gdf[\"radius_m\"] = radius\n",
    "\n",
    "    # Drop any points with insufficient observations.\n",
    "    # We can obtain a sensible threshold by dividing the hotspots\n",
    "    # radius by 30 m along-shore rates of change point distance)\n",
    "    hotspots_gdf[\"n\"] = hotspot_grouped.size()\n",
    "    hotspots_gdf = hotspots_gdf.loc[hotspots_gdf.n > (radius / 30)]\n",
    "\n",
    "    # Export hotspots to file, incrementing name for each layer\n",
    "    try:\n",
    "\n",
    "        # Set up schema to optimise file size\n",
    "        schema_dict = {\n",
    "            key: \"float:8.2\" for key in hotspots_gdf.columns if key != \"geometry\"\n",
    "        }\n",
    "        schema_dict.update(\n",
    "            {\n",
    "                \"sig_time\": \"float:8.3\",\n",
    "                \"outl_time\": \"str:80\",\n",
    "                \"radius_m\": \"int:5\",\n",
    "                \"n\": \"int:4\",\n",
    "            }\n",
    "        )\n",
    "        col_schema = schema_dict.items()\n",
    "\n",
    "        # Export file\n",
    "        layer_name = f\"hotspots_zoom_{range(0, 10)[i + 1]}\"\n",
    "        hotspots_gdf.to_file(\n",
    "            OUTPUT_FILE,\n",
    "            layer=layer_name,\n",
    "            schema={\"properties\": col_schema, \"geometry\": \"Point\"},\n",
    "        )\n",
    "\n",
    "    except ValueError as e:\n",
    "\n",
    "        print(f\"Failed to generate hotspots with error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert styles table into GeoPackage\n",
    "styles = gpd.read_file(STYLES_FILE)\n",
    "styles.to_file(OUTPUT_FILE, layer=\"layer_styles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Australia data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** For assistance with any of the Python code or Jupyter Notebooks in this repository, please post a [Github issue](https://github.com/GeoscienceAustralia/dea-coastlines/issues/new).\n",
    "\n",
    "**Last modified:** July 2022"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
